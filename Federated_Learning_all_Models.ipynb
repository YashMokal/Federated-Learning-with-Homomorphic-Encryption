{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHehlHqjW0D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Model\n",
        "# Assuming the datasets are 'breast-cancer (1).csv', 'breast-cancer (2).csv', 'breast-cancer (3).csv', 'breast-cancer (4).csv'\n",
        "# Replace with the actual filenames if they are different\n",
        "# prompt: same do for my manual 4 datasets, dataset1, dataset2, dataset3, dataset4 make respective clients and give accuracy, precision and all other aspects\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the datasets\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "tFNslQfuXAr9",
        "outputId": "c19859c2-ed04-470a-a711-bbb01bb2431b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c15ce890-1de5-4317-b241-64d43f69c44f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c15ce890-1de5-4317-b241-64d43f69c44f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1 (7).csv\n",
            "Saving dataset2.csv to dataset2 (7).csv\n",
            "Saving dataset3.csv to dataset3 (7).csv\n",
            "Saving dataset4.csv to dataset4 (7).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = []\n",
        "for i in range(1,5):\n",
        "  filename = f'breast-cancer ({i}).csv'\n",
        "  if filename in uploaded:\n",
        "      datasets.append(pd.read_csv(filename))\n",
        "  else:\n",
        "      print(f\"Error: {filename} not found in the uploaded files.\")\n",
        "\n",
        "\n",
        "# Concatenate all datasets into one dataframe\n",
        "if len(datasets) == 4:\n",
        "  ddata = pd.concat(datasets)\n",
        "else:\n",
        "    print(f\"Error: Not all datasets found, loaded only {len(datasets)}\")\n",
        "\n",
        "# Check the actual column names in the DataFrame\n",
        "print(ddata.columns)  # Print columns to verify the name of the target variable column\n",
        "\n",
        "# Assuming the target column is named 'diagnosis', replace with the correct column name if needed\n",
        "X = ddata.drop('diagnosis', axis=1)\n",
        "y = ddata['diagnosis']\n",
        "\n",
        "# Split data into four parts for four clients\n",
        "X_splits = np.array_split(X, 4)\n",
        "y_splits = np.array_split(y, 4)\n",
        "\n",
        "# Convert 'M' and 'B' to numerical values (e.g., 1 and 0) in y_splits\n",
        "for i in range(len(y_splits)):\n",
        "    y_splits[i] = y_splits[i].map({'M': 1, 'B': 0}).astype(float)  # Map 'M' to 1 and 'B' to 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9afMiZEXAun",
        "outputId": "a688d13e-6c79-45e3-fbb9-ff7435a48e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: breast-cancer (1).csv not found in the uploaded files.\n",
            "Error: breast-cancer (2).csv not found in the uploaded files.\n",
            "Error: breast-cancer (3).csv not found in the uploaded files.\n",
            "Error: breast-cancer (4).csv not found in the uploaded files.\n",
            "Error: Not all datasets found, loaded only 0\n",
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_train_clients(dataset_name, target_column):\n",
        "    try:\n",
        "        data = pd.read_csv(dataset_name)\n",
        "        X = data.drop(target_column, axis=1)\n",
        "        y = data[target_column].map({'M': 1, 'B': 0}).astype(float)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = KNeighborsClassifier()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        print(f\"--- Results for {dataset_name} ---\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-score: {f1}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{dataset_name}' not found.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Column '{e}' not found in the dataset. Check column name.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Assuming 'diagnosis' as the target column. Change if needed for your datasets\n",
        "target_column_name = 'diagnostic'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nuJMxoXQXA5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function for each dataset\n",
        "create_and_train_clients('dataset1 (5).csv', target_column_name) #Replace dataset1.csv\n",
        "create_and_train_clients('dataset2 (5).csv', target_column_name) #Replace dataset2.csv\n",
        "create_and_train_clients('dataset3 (5).csv', target_column_name) #Replace dataset3.csv\n",
        "create_and_train_clients('dataset4 (5).csv', target_column_name) #Replace dataset4.csv\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USkzNiyrW0Gd",
        "outputId": "89b75cbc-171c-4f4b-b7b1-5e67ede666f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7b5791560af0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Results for dataset1 (5).csv ---\n",
            "Accuracy: 0.6141078838174274\n",
            "Precision: 0.6190476190476191\n",
            "Recall: 0.5508474576271186\n",
            "F1-score: 0.5829596412556054\n",
            "Confusion Matrix:\n",
            "[[83 40]\n",
            " [53 65]]\n",
            "--- Results for dataset2 (5).csv ---\n",
            "Accuracy: 0.6443514644351465\n",
            "Precision: 0.6385542168674698\n",
            "Recall: 0.49074074074074076\n",
            "F1-score: 0.5549738219895288\n",
            "Confusion Matrix:\n",
            "[[101  30]\n",
            " [ 55  53]]\n",
            "--- Results for dataset3 (5).csv ---\n",
            "Accuracy: 0.6260504201680672\n",
            "Precision: 0.5391304347826087\n",
            "Recall: 0.6326530612244898\n",
            "F1-score: 0.5821596244131455\n",
            "Confusion Matrix:\n",
            "[[87 53]\n",
            " [36 62]]\n",
            "--- Results for dataset4 (5).csv ---\n",
            "Accuracy: 0.6744186046511628\n",
            "Precision: 0.7222222222222222\n",
            "Recall: 0.5909090909090909\n",
            "F1-score: 0.65\n",
            "Confusion Matrix:\n",
            "[[32 10]\n",
            " [18 26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN model after Encryption federated learning with homomorphic encryption on same datasets\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from google.colab import files\n",
        "\n",
        "# Install necessary libraries if not already installed\n",
        "!pip install scikit-learn\n",
        "\n",
        "def create_and_train_clients(dataset_name, target_column):\n",
        "    try:\n",
        "        data = pd.read_csv(dataset_name)\n",
        "        X = data.drop(target_column, axis=1)\n",
        "        y = data[target_column].map({'M': 1, 'B': 0}).astype(float)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = KNeighborsClassifier()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        print(f\"--- Results for {dataset_name} ---\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-score: {f1}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{dataset_name}' not found.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Column '{e}' not found in the dataset. Check column name.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Upload the datasets (make sure to upload them in the Colab environment)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming 'diagnosis' as the target column. Change if needed for your datasets\n",
        "target_column_name = 'diagnostic'  # Replace with your actual target column name\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "4nnw7pjoW0Js",
        "outputId": "43d056d3-0fcb-4aa4-a04c-d7778d1c98ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8345304c-95b4-40b7-9919-9b57534a7dd2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8345304c-95b4-40b7-9919-9b57534a7dd2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1 (6).csv\n",
            "Saving dataset2.csv to dataset2 (6).csv\n",
            "Saving dataset3.csv to dataset3 (6).csv\n",
            "Saving dataset4.csv to dataset4 (6).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function for each dataset.  REPLACE THESE WITH YOUR ACTUAL FILENAMES\n",
        "create_and_train_clients('dataset1 (6).csv', target_column_name)\n",
        "create_and_train_clients('dataset2 (6).csv', target_column_name)\n",
        "create_and_train_clients('dataset3 (6).csv', target_column_name)\n",
        "create_and_train_clients('dataset4 (6).csv', target_column_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KetgsdoOWkas",
        "outputId": "e5fe5aa7-d8ab-4af7-8253-2adf2eb3faca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Results for dataset1 (6).csv ---\n",
            "Accuracy: 0.6141078838174274\n",
            "Precision: 0.6190476190476191\n",
            "Recall: 0.5508474576271186\n",
            "F1-score: 0.5829596412556054\n",
            "Confusion Matrix:\n",
            "[[83 40]\n",
            " [53 65]]\n",
            "--- Results for dataset2 (6).csv ---\n",
            "Accuracy: 0.6443514644351465\n",
            "Precision: 0.6385542168674698\n",
            "Recall: 0.49074074074074076\n",
            "F1-score: 0.5549738219895288\n",
            "Confusion Matrix:\n",
            "[[101  30]\n",
            " [ 55  53]]\n",
            "--- Results for dataset3 (6).csv ---\n",
            "Accuracy: 0.6260504201680672\n",
            "Precision: 0.5391304347826087\n",
            "Recall: 0.6326530612244898\n",
            "F1-score: 0.5821596244131455\n",
            "Confusion Matrix:\n",
            "[[87 53]\n",
            " [36 62]]\n",
            "--- Results for dataset4 (6).csv ---\n",
            "Accuracy: 0.6744186046511628\n",
            "Precision: 0.7222222222222222\n",
            "Recall: 0.5909090909090909\n",
            "F1-score: 0.65\n",
            "Confusion Matrix:\n",
            "[[32 10]\n",
            " [18 26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FUAC7R0Wkx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree Fed\n",
        "!pip install syft\n",
        "!pip install tenseal\n",
        "!pip install scikit-learn\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import tenseal as ts\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import syft as sy\n",
        "# Upload the dataset file\n",
        "# Import the necessary library and function\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the dataset file\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhdivfW7fWki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "729e1a70-6226-4915-9bf8-941c3b49601f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from syft) (75.1.0)\n",
            "Requirement already satisfied: bcrypt==4.1.2 in /usr/local/lib/python3.10/dist-packages (from syft) (4.1.2)\n",
            "Requirement already satisfied: boto3==1.34.56 in /usr/local/lib/python3.10/dist-packages (from syft) (1.34.56)\n",
            "Requirement already satisfied: forbiddenfruit==0.1.4 in /usr/local/lib/python3.10/dist-packages (from syft) (0.1.4)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from syft) (24.2)\n",
            "Requirement already satisfied: pyarrow==17.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (17.0.0)\n",
            "Requirement already satisfied: pycapnp==2.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.0)\n",
            "Requirement already satisfied: pydantic==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic[email]==2.6.0->syft) (2.6.0)\n",
            "Requirement already satisfied: pydantic-settings==2.2.1 in /usr/local/lib/python3.10/dist-packages (from syft) (2.2.1)\n",
            "Requirement already satisfied: pynacl==1.5.0 in /usr/local/lib/python3.10/dist-packages (from syft) (1.5.0)\n",
            "Requirement already satisfied: pyzmq<=25.1.1,>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from syft) (24.0.1)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.10/dist-packages (from syft) (2.32.3)\n",
            "Requirement already satisfied: RestrictedPython==7.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.0)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (from syft) (4.66.4)\n",
            "Requirement already satisfied: typeguard==4.1.5 in /usr/local/lib/python3.10/dist-packages (from syft) (4.1.5)\n",
            "Requirement already satisfied: typing-extensions==4.12.0 in /usr/local/lib/python3.10/dist-packages (from syft) (4.12.0)\n",
            "Requirement already satisfied: sherlock==0.4.1 in /usr/local/lib/python3.10/dist-packages (from sherlock[filelock]==0.4.1->syft) (0.4.1)\n",
            "Requirement already satisfied: uvicorn==0.30.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.30.0)\n",
            "Requirement already satisfied: markdown==3.5.2 in /usr/local/lib/python3.10/dist-packages (from syft) (3.5.2)\n",
            "Requirement already satisfied: fastapi==0.111.0 in /usr/local/lib/python3.10/dist-packages (from syft) (0.111.0)\n",
            "Requirement already satisfied: psutil==6.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (6.0.0)\n",
            "Requirement already satisfied: itables==1.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (1.7.1)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.10/dist-packages (from syft) (23.1.0)\n",
            "Requirement already satisfied: matplotlib<3.9.1,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (3.8.0)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (from syft) (2.2.2)\n",
            "Requirement already satisfied: docker==7.1.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.1.0)\n",
            "Requirement already satisfied: kr8s==0.13.5 in /usr/local/lib/python3.10/dist-packages (from syft) (0.13.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from syft) (6.0.1)\n",
            "Requirement already satisfied: azure-storage-blob==12.19.1 in /usr/local/lib/python3.10/dist-packages (from syft) (12.19.1)\n",
            "Requirement already satisfied: ipywidgets==8.1.2 in /usr/local/lib/python3.10/dist-packages (from syft) (8.1.2)\n",
            "Requirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.1)\n",
            "Requirement already satisfied: tomli-w==1.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (1.0.0)\n",
            "Requirement already satisfied: rich==13.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (13.7.1)\n",
            "Requirement already satisfied: jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from syft) (3.1.4)\n",
            "Requirement already satisfied: tenacity==8.3.0 in /usr/local/lib/python3.10/dist-packages (from syft) (8.3.0)\n",
            "Requirement already satisfied: nh3==0.2.17 in /usr/local/lib/python3.10/dist-packages (from syft) (0.2.17)\n",
            "Requirement already satisfied: psycopg==3.1.19 in /usr/local/lib/python3.10/dist-packages (from psycopg[binary]==3.1.19->syft) (3.1.19)\n",
            "Requirement already satisfied: ipython<8.27.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.34.0)\n",
            "Requirement already satisfied: dynaconf==3.2.6 in /usr/local/lib/python3.10/dist-packages (from syft) (3.2.6)\n",
            "Requirement already satisfied: sqlalchemy==2.0.32 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.32)\n",
            "Requirement already satisfied: psycopg2-binary==2.9.9 in /usr/local/lib/python3.10/dist-packages (from syft) (2.9.9)\n",
            "Requirement already satisfied: numpy<=1.24.4,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from syft) (1.24.4)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi==23.1.0->syft) (21.2.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (1.32.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (43.0.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (0.7.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.56 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (1.34.162)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (0.10.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==7.1.0->syft) (2.2.3)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.0.5)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.27.2)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.0.17)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (5.10.0)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (3.10.11)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (2.2.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (0.2.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (3.0.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.4->syft) (3.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (3.11.2)\n",
            "Requirement already satisfied: anyio>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (3.7.1)\n",
            "Requirement already satisfied: asyncache>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (0.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (1.2.2)\n",
            "Requirement already satisfied: python-box>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (7.2.0)\n",
            "Requirement already satisfied: python-jsonpath>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->syft) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->syft) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->syft) (2024.2)\n",
            "Requirement already satisfied: psycopg-binary==3.1.19 in /usr/local/lib/python3.10/dist-packages (from psycopg[binary]==3.1.19->syft) (3.1.19)\n",
            "Requirement already satisfied: psycopg-pool in /usr/local/lib/python3.10/dist-packages (from psycopg[pool]==3.1.19->syft) (3.2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.0->pydantic[email]==2.6.0->syft) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.0->pydantic[email]==2.6.0->syft) (2.16.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings==2.2.1->syft) (1.0.1)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl==1.5.0->syft) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->syft) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->syft) (2.18.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from sherlock[filelock]==0.4.1->syft) (3.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy==2.0.32->syft) (3.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.30.0->uvicorn[standard]==0.30.0->syft) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.30.0->uvicorn[standard]==0.30.0->syft) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (14.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (3.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (4.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.7.0->kr8s==0.13.5->syft) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0.0,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from asyncache>=0.3.1->kr8s==0.13.5->syft) (5.5.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob==12.19.1->syft) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl==1.5.0->syft) (2.22)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi==0.111.0->syft) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi==0.111.0->syft) (0.13.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi==0.111.0->syft) (1.0.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.27.0->syft) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->syft) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.27.0->syft) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.27.0->syft) (0.2.13)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi==0.111.0->syft) (1.5.4)\n",
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d2abe975-a233-48b8-832a-51684a5f52d0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d2abe975-a233-48b8-832a-51684a5f52d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving breast-cancer.csv to breast-cancer (5).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (assuming the name is 'breast-cancer (4).csv')\n",
        "data = uploaded['breast-cancer (5).csv']\n",
        "# Load the dataset (assuming the name is 'breast-cancer (1).csv')\n",
        "# data = uploaded['breast-cancer (1).csv'] # This line may be redundant\n",
        "ddata = pd.read_csv('breast-cancer (5).csv')\n",
        "\n",
        "# Check the actual column names in the DataFrame\n",
        "print(ddata.columns)  # Print columns to verify the name of the target variable column\n",
        "\n",
        "# Assuming the target column is named differently, say 'diagnosis',\n",
        "# replace 'target' with the correct column name\n",
        "# For example, if the target column is named 'diagnosis':\n",
        "X = ddata.drop('diagnosis', axis=1)\n",
        "y = ddata['diagnosis']\n",
        "import numpy as np # Import numpy and assign it the alias 'np'\n",
        "# Split data into four parts for four clients\n",
        "X_splits = np.array_split(X, 4)\n",
        "y_splits = np.array_split(y, 4)\n",
        "# Encrypt data using TenSEAL\n",
        "# ... (your existing code for loading and splitting data) ...\n",
        "\n",
        "# Convert 'M' and 'B' to numerical values (e.g., 1 and 0) in y_splits\n",
        "for i in range(len(y_splits)):\n",
        "    y_splits[i] = y_splits[i].map({'M': 1, 'B': 0}).astype(float)  # Map 'M' to 1 and 'B' to 0\n",
        "\n",
        "# Encrypt data using TenSEAL\n",
        "context = ts\n",
        "class Client:\n",
        "    def __init__(self, id, X, y):\n",
        "        self.id = id\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = DecisionTreeClassifier()\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return X_test, y_test\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, id, X, y):\n",
        "        self.id = id\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = DecisionTreeClassifier()\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return X_test, y_test\n",
        "\n",
        "\n",
        "# Create clients\n",
        "clients = [Client(f\"client_{i}\", X_splits[i], y_splits[i]) for i in range(4)]\n",
        "# Train models on each client\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "for client in clients:\n",
        "    X_test, y_test = client.train()\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "# Aggregate models (simple averaging for demonstration)\n",
        "import numpy as np\n",
        "\n",
        "# Aggregate models by averaging predictions instead of the tree structure directly\n",
        "def aggregate_predictions(clients, X):\n",
        "  \"\"\"\n",
        "  Aggregates predictions from multiple clients.\n",
        "\n",
        "  Args:\n",
        "    clients: List of Client objects.\n",
        "    X: Input data for prediction.\n",
        "\n",
        "  Returns:\n",
        "    Averaged predictions.\n",
        "  \"\"\"\n",
        "  all_predictions = [client.model.predict(X) for client in clients]\n",
        "  # Assuming all_predictions is a list of numpy arrays\n",
        "  return np.mean(all_predictions, axis=0)\n",
        "\n",
        "\n",
        "# Assuming you have X_splits, y_splits and clients defined as before\n",
        "\n",
        "# Train models on each client\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "for client in clients:\n",
        "    X_test, y_test = client.train()\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# Instead of averaging tree structures, average predictions:\n",
        "# final_model.tree_ = sum([client.model.tree_ for client in clients]) / 4  # Remove this line\n",
        "\n",
        "# Example usage for prediction:\n",
        "predictions = aggregate_predictions(clients, X_tests[0])  # Predict on the first client's test data\n",
        "\n",
        "# Evaluate the final model\n",
        "# ... (Client class and other code remains the same) ...\n",
        "\n",
        "# Instead of directly using final_model.predict, use aggregate_predictions:\n",
        "X_test_combined = pd.concat(X_tests)\n",
        "y_test_combined = pd.concat(y_tests)\n",
        "#y_pred = final_model.predict(X_test_combined)  # Remove this line\n",
        "y_pred = aggregate_predictions(clients, X_test_combined) # Use the aggregate_predictions function\n",
        "\n",
        "# Convert y_pred to binary predictions (0 or 1) by thresholding\n",
        "y_pred = (y_pred >= 0.5).astype(int)  # Assuming 0.5 as the threshold\n",
        "\n",
        "accuracy = accuracy_score(y_test_combined, y_pred)\n",
        "\n",
        "print(f\"Final model accuracy: {accuracy}\")\n",
        "# Instead of directly using final_model.predict, use aggregate_predictions:\n",
        "X_test_combined = pd.concat(X_tests)\n",
        "y_test_combined = pd.concat(y_tests)\n",
        "y_pred = aggregate_predictions(clients, X_test_combined) # Use the aggregate_predictions function\n",
        "\n",
        "# Convert y_pred to binary predictions (0 or 1) by thresholding\n",
        "y_pred = (y_pred >= 0.5).astype(int)  # Assuming 0.5 as the threshold\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test_combined, y_pred)\n",
        "precision = precision_score(y_test_combined, y_pred)\n",
        "recall = recall_score(y_test_combined, y_pred)\n",
        "f1 = f1_score(y_test_combined, y_pred)\n",
        "cm = confusion_matrix(y_test_combined, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50OJHv6aGheI",
        "outputId": "4abe8d07-5c1d-47bd-cc2d-5eb3a0878827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst'],\n",
            "      dtype='object')\n",
            "Final model accuracy: 0.9137931034482759\n",
            "Accuracy: 0.9137931034482759\n",
            "Precision: 0.8333333333333334\n",
            "Recall: 0.9523809523809523\n",
            "F1-score: 0.8888888888888888\n",
            "Confusion Matrix:\n",
            "[[66  8]\n",
            " [ 2 40]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 datasets, dataset1, dataset2, dataset3, dataset4 make respective clients and give accuracy, precision and all other aspects\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the datasets\n",
        "uploaded = files.upload() #select all 4 datasets at a time i.e; dataset1, dataset2, dataset3, dataset4\n",
        "\n",
        "def create_and_train_clients(dataset_name, target_column):\n",
        "    try:\n",
        "        data = pd.read_csv(dataset_name)\n",
        "        X = data.drop(target_column, axis=1)\n",
        "        y = data[target_column].map({'M': 1, 'B': 0}).astype(float)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = DecisionTreeClassifier()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        print(f\"--- Results for {dataset_name} ---\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-score: {f1}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{dataset_name}' not found.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Column '{e}' not found in the dataset. Check column name.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Assuming 'diagnosis' as the target column. Change if needed for your datasets\n",
        "target_column_name = 'diagnostic'\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "q105EGMMHf0e",
        "outputId": "a73d0834-5951-4221-b0d9-16441f4f7832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9f9260bb-bc94-4cd4-a386-8aaea7b5ba24\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9f9260bb-bc94-4cd4-a386-8aaea7b5ba24\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1 (2).csv\n",
            "Saving dataset2.csv to dataset2 (2).csv\n",
            "Saving dataset3.csv to dataset3 (2).csv\n",
            "Saving dataset4.csv to dataset4 (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function for each dataset\n",
        "create_and_train_clients('dataset1 (2).csv', target_column_name) #Replace dataset1.csv\n",
        "create_and_train_clients('dataset2 (2).csv', target_column_name) #Replace dataset2.csv\n",
        "create_and_train_clients('dataset3 (2).csv', target_column_name) #Replace dataset3.csv\n",
        "create_and_train_clients('dataset4 (2).csv', target_column_name) #Replace dataset4.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeEluNoHHf8W",
        "outputId": "e22a49e1-6751-407a-fefe-0f983d2e069d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Results for dataset1 (2).csv ---\n",
            "Accuracy: 0.983402489626556\n",
            "Precision: 0.9830508474576272\n",
            "Recall: 0.9830508474576272\n",
            "F1-score: 0.9830508474576272\n",
            "Confusion Matrix:\n",
            "[[121   2]\n",
            " [  2 116]]\n",
            "--- Results for dataset2 (2).csv ---\n",
            "Accuracy: 0.9832635983263598\n",
            "Precision: 0.9727272727272728\n",
            "Recall: 0.9907407407407407\n",
            "F1-score: 0.981651376146789\n",
            "Confusion Matrix:\n",
            "[[128   3]\n",
            " [  1 107]]\n",
            "--- Results for dataset3 (2).csv ---\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Confusion Matrix:\n",
            "[[140   0]\n",
            " [  0  98]]\n",
            "--- Results for dataset4 (2).csv ---\n",
            "Accuracy: 0.9651162790697675\n",
            "Precision: 0.9767441860465116\n",
            "Recall: 0.9545454545454546\n",
            "F1-score: 0.9655172413793104\n",
            "Confusion Matrix:\n",
            "[[41  1]\n",
            " [ 2 42]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform federated learning with homographic encryption on same datasets\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the datasets\n",
        "uploaded = files.upload() #select all 4 datasets at a time i.e; dataset1, dataset2, dataset3, dataset4\n",
        "\n",
        "def create_and_train_clients(dataset_name, target_column):\n",
        "    try:\n",
        "        data = pd.read_csv(dataset_name)\n",
        "        X = data.drop(target_column, axis=1)\n",
        "        y = data[target_column].map({'M': 1, 'B': 0}).astype(float)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        model = DecisionTreeClassifier()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        print(f\"--- Results for {dataset_name} ---\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-score: {f1}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{dataset_name}' not found.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Column '{e}' not found in the dataset. Check column name.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Assuming 'diagnosis' as the target column. Change if needed for your datasets\n",
        "target_column_name = 'diagnostic' # Or the correct column name from your dataset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "oj5X0f-sGhmy",
        "outputId": "2e5c2a8b-61c4-45f7-823d-7155e0e903b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-39ee377e-033c-4ef1-8d69-18d17c3d5b16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-39ee377e-033c-4ef1-8d69-18d17c3d5b16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1 (4).csv\n",
            "Saving dataset2.csv to dataset2 (4).csv\n",
            "Saving dataset3.csv to dataset3 (4).csv\n",
            "Saving dataset4.csv to dataset4 (4).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install phe\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from phe import paillier\n",
        "\n",
        "def create_and_train_clients_with_encryption(dataset_name, target_column):\n",
        "    try:\n",
        "        # Load dataset\n",
        "        data = pd.read_csv(dataset_name)\n",
        "        X = data.drop(target_column, axis=1)\n",
        "        y = data[target_column].map({'M': 1, 'B': 0}).astype(float)\n",
        "\n",
        "        # Split data into train and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Generate Paillier encryption keys\n",
        "        public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "        # Encrypt labels (y_train) using public key\n",
        "        y_train_encrypted = [public_key.encrypt(label) for label in y_train]\n",
        "\n",
        "        # Train the model (this is tricky, as homomorphic encryption works differently)\n",
        "        # For the sake of simplicity, we're not actually doing encrypted training, since\n",
        "        # DecisionTreeClassifier doesn't natively support encrypted inputs.\n",
        "        # Here, it's just a placeholder for integration with a homomorphic encryption-enabled model.\n",
        "\n",
        "        model = DecisionTreeClassifier()\n",
        "        model.fit(X_train, y_train)  # Note: real encrypted training would differ!\n",
        "\n",
        "        # Test the model\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        print(f\"--- Results for {dataset_name} ---\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-score: {f1}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "        # Decrypt one of the encrypted labels for demonstration\n",
        "        decrypted_label = private_key.decrypt(y_train_encrypted[0])\n",
        "        print(f\"Decrypted label (first sample in train set): {decrypted_label}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{dataset_name}' not found.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Column '{e}' not found in the dataset. Check column name.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "target_column_name = 'diagnostic'  # Change this to your dataset's target column\n",
        "create_and_train_clients_with_encryption('dataset1 (4).csv', target_column_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKJKJEM4JR3y",
        "outputId": "962c2aaa-e4dc-4856-c40c-f843edd62763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phe in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "--- Results for dataset1 (4).csv ---\n",
            "Accuracy: 0.9875518672199171\n",
            "Precision: 0.9914529914529915\n",
            "Recall: 0.9830508474576272\n",
            "F1-score: 0.9872340425531915\n",
            "Confusion Matrix:\n",
            "[[122   1]\n",
            " [  2 116]]\n",
            "Decrypted label (first sample in train set): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OD3jF9WDJR6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "# Necessary Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e7oC8Qe_gDpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the datasets manually (one for each client)\n",
        "print(\"Upload dataset1.csv for Client 1\")\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "print(\"Upload dataset2.csv for Client 2\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "print(\"Upload dataset3.csv for Client 3\")\n",
        "uploaded3 = files.upload()\n",
        "\n",
        "print(\"Upload dataset4.csv for Client 4\")\n",
        "uploaded4 = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "qqRokCO1FOQ7",
        "outputId": "333a4a5c-0de2-4fa9-fcbc-8f814a8e26b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload dataset1.csv for Client 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a17490e-8af6-4a85-81b8-00b8f77ce102\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a17490e-8af6-4a85-81b8-00b8f77ce102\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1.csv\n",
            "Upload dataset2.csv for Client 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fbfc5cd5-90aa-42f0-9986-d78a524ec16a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fbfc5cd5-90aa-42f0-9986-d78a524ec16a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset2.csv to dataset2.csv\n",
            "Upload dataset3.csv for Client 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cb222d43-22e3-4837-80a9-99b87bdcf0e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cb222d43-22e3-4837-80a9-99b87bdcf0e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset3.csv to dataset3.csv\n",
            "Upload dataset4.csv for Client 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9345f990-13a6-430e-9f33-17865c0132fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9345f990-13a6-430e-9f33-17865c0132fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset4.csv to dataset4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all datasets manually\n",
        "dataset1 = pd.read_csv('dataset1.csv')\n",
        "dataset2 = pd.read_csv('dataset2.csv')\n",
        "dataset3 = pd.read_csv('dataset3.csv')\n",
        "dataset4 = pd.read_csv('dataset4.csv')\n",
        "\n",
        "# Function to preprocess each dataset (scaling, train-test split, etc.)\n",
        "def scale_dataset(df, overSample=False):\n",
        "    # Replace \"M\" with 1 and \"B\" with 0 at \"diagnosis\" column\n",
        "    df[\"diagnostic\"] = (df[\"diagnostic\"] == \"M\").astype(int)\n",
        "\n",
        "    # split to features and target\n",
        "    X = df[df.columns[:-1]].values\n",
        "    Y = df[df.columns[-1]].values\n",
        "\n",
        "    # standardize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    data = np.hstack((X, np.reshape(Y, (-1, 1))))\n",
        "\n",
        "    # Convert to PyTorch tensor\n",
        "    X_tensor = Variable(torch.tensor(X, dtype=torch.float32))\n",
        "    Y_tensor = Variable(torch.tensor(Y, dtype=torch.float32))\n",
        "\n",
        "    return X_tensor, Y_tensor\n",
        "\n",
        "\n",
        "# Split all datasets to features (X) and targets (Y)\n",
        "X1, Y1 = scale_dataset(dataset1)\n",
        "X2, Y2 = scale_dataset(dataset2)\n",
        "X3, Y3 = scale_dataset(dataset3)\n",
        "X4, Y4 = scale_dataset(dataset4)\n",
        "\n",
        "# Client class for local training\n",
        "class Client:\n",
        "    def __init__(self, X_train, Y_train, name):\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.name = name\n",
        "        self.local_model = LogisticRegression()\n",
        "\n",
        "    def local_training(self):\n",
        "        # Convert tensors to numpy for scikit-learn logistic regression\n",
        "        X_np = self.X_train.detach().numpy()\n",
        "        Y_np = self.Y_train.detach().numpy()\n",
        "\n",
        "        # Train logistic regression on local data\n",
        "        self.local_model.fit(X_np, Y_np)\n",
        "\n",
        "    def get_params(self):\n",
        "        # Get local model coefficients (weights) and intercept (bias)\n",
        "        return self.local_model.coef_, self.local_model.intercept_\n",
        "\n",
        "    def set_params(self, coef, intercept):\n",
        "        # Set model parameters (coefficients and intercept)\n",
        "        self.local_model.coef_ = coef\n",
        "        self.local_model.intercept_ = intercept\n",
        "\n",
        "    def evaluate(self, X_test, Y_test):\n",
        "        # Evaluate model on test set\n",
        "        X_np = X_test.detach().numpy()\n",
        "        Y_np = Y_test.detach().numpy()\n",
        "        predictions = self.local_model.predict(X_np)\n",
        "        accuracy = accuracy_score(Y_np, predictions)\n",
        "        print(f'{self.name} Accuracy: {accuracy * 100:.2f}%')\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "# Instantiate clients\n",
        "client1 = Client(X1, Y1, \"Client 1\")\n",
        "client2 = Client(X2, Y2, \"Client 2\")\n",
        "client3 = Client(X3, Y3, \"Client 3\")\n",
        "client4 = Client(X4, Y4, \"Client 4\")\n",
        "\n",
        "clients = [client1, client2, client3, client4]\n",
        "\n",
        "\n",
        "# Federated averaging function\n",
        "def federated_averaging(clients):\n",
        "    total_samples = sum(len(client.X_train) for client in clients)\n",
        "    new_weights = None\n",
        "    new_intercept = None\n",
        "\n",
        "    for client in clients:\n",
        "        client_samples = len(client.X_train)\n",
        "        coef, intercept = client.get_params()\n",
        "\n",
        "        if new_weights is None:\n",
        "            new_weights = coef * client_samples / total_samples\n",
        "            new_intercept = intercept * client_samples / total_samples\n",
        "        else:\n",
        "            new_weights += coef * client_samples / total_samples\n",
        "            new_intercept += intercept * client_samples / total_samples\n",
        "\n",
        "    # Update all clients with the new averaged parameters\n",
        "    for client in clients:\n",
        "        client.set_params(new_weights, new_intercept)\n",
        "\n",
        "\n",
        "  # Training loop for federated learning\n",
        "def federated_training(clients, num_rounds=10):\n",
        "    for round_num in range(num_rounds):\n",
        "        print(f\"\\nRound {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "        # Each client performs local training\n",
        "        for client in clients:\n",
        "            client.local_training()\n",
        "\n",
        "        # Federated averaging\n",
        "        federated_averaging(clients)\n",
        "\n",
        "        # Evaluate each client after federated averaging\n",
        "        for client in clients:\n",
        "            client.evaluate(client.X_train, client.Y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_with_metrics(client, X_test, Y_test):\n",
        "    X_np = X_test.detach().numpy()\n",
        "    Y_np = Y_test.detach().numpy()\n",
        "    predictions = client.local_model.predict(X_np)\n",
        "\n",
        "    accuracy = accuracy_score(Y_np, predictions)\n",
        "    precision = precision_score(Y_np, predictions)\n",
        "    recall = recall_score(Y_np, predictions)\n",
        "    f1 = f1_score(Y_np, predictions)\n",
        "\n",
        "    print(f'{client.name} Accuracy: {accuracy * 100:.2f}%')\n",
        "    print(f'{client.name} Precision: {precision:.2f}')\n",
        "    print(f'{client.name} Recall: {recall:.2f}')\n",
        "    print(f'{client.name} F1-score: {f1:.2f}')\n",
        "\n",
        "    print(f'\\n{client.name} Classification Report:\\n{classification_report(Y_np, predictions)}')\n",
        "    print(f'\\n{client.name} Confusion Matrix:\\n{confusion_matrix(Y_np, predictions)}')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "# Modify the federated_training function to include evaluation with metrics\n",
        "def federated_training_with_metrics(clients, num_rounds=10):\n",
        "    for round_num in range(num_rounds):\n",
        "        print(f\"\\nRound {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "        # Each client performs local training\n",
        "        for client in clients:\n",
        "            client.local_training()\n",
        "\n",
        "        # Federated averaging\n",
        "        federated_averaging(clients)\n",
        "\n",
        "        # Evaluate each client after federated averaging with metrics\n",
        "        for client in clients:\n",
        "            evaluate_with_metrics(client, client.X_train, client.Y_train)\n",
        "\n",
        "\n",
        "# Perform federated training with metrics\n",
        "federated_training_with_metrics(clients, num_rounds=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cztZw33LFm6q",
        "outputId": "dda8dcd8-353b-4851-9532-b368377cf28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 2/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 3/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 4/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 5/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 6/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 7/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 8/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 9/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 10/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 11/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 12/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 13/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 14/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 15/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 16/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 17/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 18/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 19/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 20/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 21/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 22/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 23/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 24/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 25/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 26/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 27/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 28/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 29/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 30/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 31/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 32/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 33/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 34/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 35/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 36/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 37/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 38/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 39/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 40/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 41/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 42/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 43/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 44/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 45/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 46/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 47/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 48/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 49/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n",
            "\n",
            "Round 50/50\n",
            "Client 1 Accuracy: 99.42%\n",
            "Client 1 Precision: 1.00\n",
            "Client 1 Recall: 0.99\n",
            "Client 1 F1-score: 0.99\n",
            "\n",
            "Client 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       629\n",
            "         1.0       1.00      0.99      0.99       573\n",
            "\n",
            "    accuracy                           0.99      1202\n",
            "   macro avg       0.99      0.99      0.99      1202\n",
            "weighted avg       0.99      0.99      0.99      1202\n",
            "\n",
            "\n",
            "Client 1 Confusion Matrix:\n",
            "[[627   2]\n",
            " [  5 568]]\n",
            "Client 2 Accuracy: 99.75%\n",
            "Client 2 Precision: 1.00\n",
            "Client 2 Recall: 0.99\n",
            "Client 2 F1-score: 1.00\n",
            "\n",
            "Client 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       617\n",
            "         1.0       1.00      0.99      1.00       576\n",
            "\n",
            "    accuracy                           1.00      1193\n",
            "   macro avg       1.00      1.00      1.00      1193\n",
            "weighted avg       1.00      1.00      1.00      1193\n",
            "\n",
            "\n",
            "Client 2 Confusion Matrix:\n",
            "[[617   0]\n",
            " [  3 573]]\n",
            "Client 3 Accuracy: 99.75%\n",
            "Client 3 Precision: 1.00\n",
            "Client 3 Recall: 0.99\n",
            "Client 3 F1-score: 1.00\n",
            "\n",
            "Client 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       614\n",
            "         1.0       1.00      0.99      1.00       575\n",
            "\n",
            "    accuracy                           1.00      1189\n",
            "   macro avg       1.00      1.00      1.00      1189\n",
            "weighted avg       1.00      1.00      1.00      1189\n",
            "\n",
            "\n",
            "Client 3 Confusion Matrix:\n",
            "[[614   0]\n",
            " [  3 572]]\n",
            "Client 4 Accuracy: 99.06%\n",
            "Client 4 Precision: 1.00\n",
            "Client 4 Recall: 0.98\n",
            "Client 4 F1-score: 0.99\n",
            "\n",
            "Client 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99       222\n",
            "         1.0       1.00      0.98      0.99       204\n",
            "\n",
            "    accuracy                           0.99       426\n",
            "   macro avg       0.99      0.99      0.99       426\n",
            "weighted avg       0.99      0.99      0.99       426\n",
            "\n",
            "\n",
            "Client 4 Confusion Matrix:\n",
            "[[222   0]\n",
            " [  4 200]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After encryption Logistic Regression\n",
        "!pip install pandas scikit-learn syft tenseal\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import syft as sy\n",
        "import tenseal as ts\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the dataset file\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zIC8MD8JFOTp",
        "outputId": "5987d172-80e9-4dd0-b7be-adea4611d5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: syft in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.15)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from syft) (75.1.0)\n",
            "Requirement already satisfied: bcrypt==4.1.2 in /usr/local/lib/python3.10/dist-packages (from syft) (4.1.2)\n",
            "Requirement already satisfied: boto3==1.34.56 in /usr/local/lib/python3.10/dist-packages (from syft) (1.34.56)\n",
            "Requirement already satisfied: forbiddenfruit==0.1.4 in /usr/local/lib/python3.10/dist-packages (from syft) (0.1.4)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from syft) (24.2)\n",
            "Requirement already satisfied: pyarrow==17.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (17.0.0)\n",
            "Requirement already satisfied: pycapnp==2.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.0)\n",
            "Requirement already satisfied: pydantic==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic[email]==2.6.0->syft) (2.6.0)\n",
            "Requirement already satisfied: pydantic-settings==2.2.1 in /usr/local/lib/python3.10/dist-packages (from syft) (2.2.1)\n",
            "Requirement already satisfied: pynacl==1.5.0 in /usr/local/lib/python3.10/dist-packages (from syft) (1.5.0)\n",
            "Requirement already satisfied: pyzmq<=25.1.1,>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from syft) (24.0.1)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.10/dist-packages (from syft) (2.32.3)\n",
            "Requirement already satisfied: RestrictedPython==7.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.0)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (from syft) (4.66.4)\n",
            "Requirement already satisfied: typeguard==4.1.5 in /usr/local/lib/python3.10/dist-packages (from syft) (4.1.5)\n",
            "Requirement already satisfied: typing-extensions==4.12.0 in /usr/local/lib/python3.10/dist-packages (from syft) (4.12.0)\n",
            "Requirement already satisfied: sherlock==0.4.1 in /usr/local/lib/python3.10/dist-packages (from sherlock[filelock]==0.4.1->syft) (0.4.1)\n",
            "Requirement already satisfied: uvicorn==0.30.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.30.0)\n",
            "Requirement already satisfied: markdown==3.5.2 in /usr/local/lib/python3.10/dist-packages (from syft) (3.5.2)\n",
            "Requirement already satisfied: fastapi==0.111.0 in /usr/local/lib/python3.10/dist-packages (from syft) (0.111.0)\n",
            "Requirement already satisfied: psutil==6.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (6.0.0)\n",
            "Requirement already satisfied: itables==1.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (1.7.1)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.10/dist-packages (from syft) (23.1.0)\n",
            "Requirement already satisfied: matplotlib<3.9.1,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (3.8.0)\n",
            "Requirement already satisfied: docker==7.1.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.1.0)\n",
            "Requirement already satisfied: kr8s==0.13.5 in /usr/local/lib/python3.10/dist-packages (from syft) (0.13.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from syft) (6.0.1)\n",
            "Requirement already satisfied: azure-storage-blob==12.19.1 in /usr/local/lib/python3.10/dist-packages (from syft) (12.19.1)\n",
            "Requirement already satisfied: ipywidgets==8.1.2 in /usr/local/lib/python3.10/dist-packages (from syft) (8.1.2)\n",
            "Requirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.1)\n",
            "Requirement already satisfied: tomli-w==1.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (1.0.0)\n",
            "Requirement already satisfied: rich==13.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (13.7.1)\n",
            "Requirement already satisfied: jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from syft) (3.1.4)\n",
            "Requirement already satisfied: tenacity==8.3.0 in /usr/local/lib/python3.10/dist-packages (from syft) (8.3.0)\n",
            "Requirement already satisfied: nh3==0.2.17 in /usr/local/lib/python3.10/dist-packages (from syft) (0.2.17)\n",
            "Requirement already satisfied: psycopg==3.1.19 in /usr/local/lib/python3.10/dist-packages (from psycopg[binary]==3.1.19->syft) (3.1.19)\n",
            "Requirement already satisfied: ipython<8.27.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.34.0)\n",
            "Requirement already satisfied: dynaconf==3.2.6 in /usr/local/lib/python3.10/dist-packages (from syft) (3.2.6)\n",
            "Requirement already satisfied: sqlalchemy==2.0.32 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.32)\n",
            "Requirement already satisfied: psycopg2-binary==2.9.9 in /usr/local/lib/python3.10/dist-packages (from syft) (2.9.9)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi==23.1.0->syft) (21.2.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (1.32.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (43.0.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (0.7.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.56 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (1.34.162)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (0.10.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==7.1.0->syft) (2.2.3)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.0.5)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.27.2)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.0.17)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (5.10.0)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (3.10.11)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (2.2.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (0.2.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (3.0.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.4->syft) (3.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (3.11.2)\n",
            "Requirement already satisfied: anyio>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (3.7.1)\n",
            "Requirement already satisfied: asyncache>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (0.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (1.2.2)\n",
            "Requirement already satisfied: python-box>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (7.2.0)\n",
            "Requirement already satisfied: python-jsonpath>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (1.2.0)\n",
            "Requirement already satisfied: psycopg-binary==3.1.19 in /usr/local/lib/python3.10/dist-packages (from psycopg[binary]==3.1.19->syft) (3.1.19)\n",
            "Requirement already satisfied: psycopg-pool in /usr/local/lib/python3.10/dist-packages (from psycopg[pool]==3.1.19->syft) (3.2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.0->pydantic[email]==2.6.0->syft) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.0->pydantic[email]==2.6.0->syft) (2.16.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings==2.2.1->syft) (1.0.1)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl==1.5.0->syft) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->syft) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->syft) (2.18.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from sherlock[filelock]==0.4.1->syft) (3.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy==2.0.32->syft) (3.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.30.0->uvicorn[standard]==0.30.0->syft) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.30.0->uvicorn[standard]==0.30.0->syft) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (14.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (4.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.7.0->kr8s==0.13.5->syft) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0.0,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from asyncache>=0.3.1->kr8s==0.13.5->syft) (5.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl==1.5.0->syft) (2.22)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi==0.111.0->syft) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi==0.111.0->syft) (0.13.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi==0.111.0->syft) (1.0.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.27.0->syft) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->syft) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.27.0->syft) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.27.0->syft) (0.2.13)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi==0.111.0->syft) (1.5.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd91d5c0-ded9-4301-a4c5-eb3d935b3660\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd91d5c0-ded9-4301-a4c5-eb3d935b3660\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving breast-cancer.csv to breast-cancer (4).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (assuming the name is 'breast-cancer (4).csv')\n",
        "data = uploaded['breast-cancer (4).csv']\n",
        "# Load the dataset (assuming the name is 'breast-cancer (1).csv')\n",
        "# data = uploaded['breast-cancer (1).csv'] # This line may be redundant\n",
        "ddata = pd.read_csv('breast-cancer (4).csv')\n",
        "\n",
        "# Check the actual column names in the DataFrame\n",
        "print(ddata.columns)  # Print columns to verify the name of the target variable column\n",
        "\n",
        "# Assuming the target column is named differently, say 'diagnosis',\n",
        "# replace 'target' with the correct column name\n",
        "# For example, if the target column is named 'diagnosis':\n",
        "X = ddata.drop('diagnosis', axis=1)\n",
        "y = ddata['diagnosis']\n",
        "\n",
        "# Split data into four parts for four clients\n",
        "import numpy as np\n",
        "X_splits = np.array_split(X, 4)\n",
        "y_splits = np.array_split(y, 4)\n",
        "\n",
        "# Encrypt data using TenSEAL\n",
        "\n",
        "\n",
        "# Convert 'M' and 'B' to numerical values (e.g., 1 and 0) in y_splits\n",
        "for i in range(len(y_splits)):\n",
        "    y_splits[i] = y_splits[i].map({'M': 1, 'B': 0}).astype(float)  # Map 'M' to 1 and 'B' to 0\n",
        "\n",
        "# Encrypt data using TenSEAL\n",
        "context = ts\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, id, X, y):\n",
        "        self.id = id\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = LogisticRegression\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return X_test, y_test\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, id, X, y):\n",
        "        self.id = id\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = LogisticRegression()\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return X_test, y_test\n",
        "\n",
        "\n",
        "# Create clients\n",
        "clients = [Client(f\"client_{i}\", X_splits[i], y_splits[i]) for i in range(4)]\n",
        "\n",
        "# Train models on each client\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "for client in clients:\n",
        "    X_test, y_test = client.train()\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "# Aggregate models (simple averaging for demonstration)\n",
        "import numpy as np\n",
        "\n",
        "# Aggregate models by averaging predictions instead of the tree structure directly\n",
        "def aggregate_predictions(clients, X):\n",
        "  \"\"\"\n",
        "  Aggregates predictions from multiple clients.\n",
        "\n",
        "  Args:\n",
        "    clients: List of Client objects.\n",
        "    X: Input data for prediction.\n",
        "\n",
        "  Returns:\n",
        "    Averaged predictions.\n",
        "  \"\"\"\n",
        "  all_predictions = [client.model.predict(X) for client in clients]\n",
        "  # Assuming all_predictions is a list of numpy arrays\n",
        "  return np.mean(all_predictions, axis=0)\n",
        "\n",
        "\n",
        "# Assuming you have X_splits, y_splits and clients defined as before\n",
        "\n",
        "# Train models on each client\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "for client in clients:\n",
        "    X_test, y_test = client.train()\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# Instead of averaging tree structures, average predictions:\n",
        "# final_model.tree_ = sum([client.model.tree_ for client in clients]) / 4  # Remove this line\n",
        "\n",
        "# Example usage for prediction:\n",
        "predictions = aggregate_predictions(clients, X_tests[0])  # Predict on the first client's test data\n",
        "\n",
        "\n",
        "# Evaluate the final model\n",
        "# ... (Client class and other code remains the same) ...\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Instead of directly using final_model.predict, use aggregate_predictions:\n",
        "X_test_combined = pd.concat(X_tests)\n",
        "y_test_combined = pd.concat(y_tests)\n",
        "y_pred = aggregate_predictions(clients, X_test_combined)\n",
        "\n",
        "# Convert y_pred to binary predictions (0 or 1) by thresholding\n",
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test_combined, y_pred)\n",
        "print(f\"Final model accuracy: {accuracy}\")\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test_combined, y_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB9NPCFqFOWN",
        "outputId": "9d03eb89-e2f1-46c8-c7b6-ba40ca580af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model accuracy: 0.9051724137931034\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.93      0.93        74\n",
            "         1.0       0.88      0.86      0.87        42\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.90      0.89      0.90       116\n",
            "weighted avg       0.90      0.91      0.90       116\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM Model\n",
        "\n",
        "!pip install phe\n",
        "  # Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from io import StringIO\n",
        "\n",
        "# Upload the dataset file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the dataset (assuming the name is 'breast-cancer (4).csv')\n",
        "data = uploaded['breast-cancer.csv']\n",
        "df = pd.read_csv(StringIO(data.decode('utf-8')))\n",
        "\n",
        "# Define a function to swap columns (if needed)\n",
        "def swap_columns(df, col1, col2):\n",
        "    col_list = list(df.columns)\n",
        "    x, y = col_list.index(col1), col_list.index(col2)\n",
        "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
        "    df = df[col_list]\n",
        "    return df\n",
        "\n",
        "# Swap columns if needed (e.g., 'diagnosis' and 'fractal_dimension_worst')\n",
        "df = swap_columns(df, 'diagnosis', 'fractal_dimension_worst')\n",
        "\n",
        "# Replace \"M\" with 1 and \"B\" with 0 in the diagnosis column\n",
        "df[\"diagnosis\"] = (df[\"diagnosis\"] == \"M\").astype(int)\n",
        "\n",
        "# Split dataframe into train and test datasets\n",
        "df_train, df_test = np.split(df.sample(frac=1), [int(0.8 * len(df))])\n",
        "\n",
        "# Import libraries for machine learning and federated learning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Scaling the dataset function\n",
        "def scale_dataset(df, overSample=False):\n",
        "    # Separate features and target\n",
        "    X = df[df.columns[:-1]].values\n",
        "    Y = df[df.columns[-1]].values\n",
        "\n",
        "    # Standardize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Balance class distribution\n",
        "    if overSample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, Y = ros.fit_resample(X, Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Scale train and test datasets\n",
        "X_train, Y_train = scale_dataset(df_train, True)\n",
        "X_test, Y_test = scale_dataset(df_test, False)\n",
        "\n",
        "# Define the SVM model class\n",
        "class SVMModel:\n",
        "    def __init__(self, kernel='linear'):\n",
        "        self.model = SVC(kernel=kernel)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        return accuracy\n",
        "\n",
        "# Federated Learning SVM implementation for multiple clients (e.g., 4 clients)\n",
        "class Client:\n",
        "    def __init__(self, name, X_train, Y_train, X_test, Y_test):\n",
        "        self.name = name\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.model = SVMModel(kernel='linear')\n",
        "\n",
        "    def local_training(self):\n",
        "        self.model.train(self.X_train, self.Y_train)\n",
        "\n",
        "    def local_evaluation(self):\n",
        "        return self.model.evaluate(self.X_test, self.Y_test)\n",
        "\n",
        "# Split data for 4 clients\n",
        "n_clients = 4\n",
        "X_train_splits = np.array_split(X_train, n_clients)\n",
        "Y_train_splits = np.array_split(Y_train, n_clients)\n",
        "\n",
        "clients = []\n",
        "for i in range(n_clients):\n",
        "    clients.append(Client(f'Client_{i+1}', X_train_splits[i], Y_train_splits[i], X_test, Y_test))\n",
        "\n",
        "\n",
        "# Federated learning process (aggregate models)\n",
        "def federated_learning(clients):\n",
        "    for client in clients:\n",
        "        print(f\"{client.name} training\")\n",
        "        client.local_training()\n",
        "        accuracy = client.local_evaluation()\n",
        "        print(f\"{client.name} accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "#   precision, recall, f1 score and all other aspects\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(client):\n",
        "    \"\"\"Evaluates the client's model and prints various metrics.\"\"\"\n",
        "\n",
        "    y_pred = client.model.predict(client.X_test)\n",
        "    y_true = client.Y_test\n",
        "\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"{client.name} Precision: {precision:.2f}\")\n",
        "    print(f\"{client.name} Recall: {recall:.2f}\")\n",
        "    print(f\"{client.name} F1-Score: {f1:.2f}\")\n",
        "\n",
        "    # Print a comprehensive classification report\n",
        "    print(f\"\\n{client.name} Classification Report:\\n\", classification_report(y_true, y_pred))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print(f\"\\n{client.name} Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Modified Federated Learning process\n",
        "def federated_learning(clients):\n",
        "    for client in clients:\n",
        "        print(f\"{client.name} training\")\n",
        "        client.local_training()\n",
        "        evaluate_model(client)  # Evaluate the model after training\n",
        "\n",
        "\n",
        "# Run federated learning with SVM and evaluation\n",
        "federated_learning(clients)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ygERXu4FAM9K",
        "outputId": "20a23229-71f8-43cd-98ce-fca3a7402855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phe\n",
            "  Downloading phe-1.5.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: phe\n",
            "Successfully installed phe-1.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c54e313e-ee40-4e32-9758-32ec4f7f8919\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c54e313e-ee40-4e32-9758-32ec4f7f8919\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving breast-cancer.csv to breast-cancer.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 training\n",
            "Client_1 Precision: 1.00\n",
            "Client_1 Recall: 0.87\n",
            "Client_1 F1-Score: 0.93\n",
            "\n",
            "Client_1 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        67\n",
            "           1       1.00      0.87      0.93        47\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "Client_1 Confusion Matrix:\n",
            " [[67  0]\n",
            " [ 6 41]]\n",
            "Client_2 training\n",
            "Client_2 Precision: 0.96\n",
            "Client_2 Recall: 0.91\n",
            "Client_2 F1-Score: 0.93\n",
            "\n",
            "Client_2 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96        67\n",
            "           1       0.96      0.91      0.93        47\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.95      0.94      0.95       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "Client_2 Confusion Matrix:\n",
            " [[65  2]\n",
            " [ 4 43]]\n",
            "Client_3 training\n",
            "Client_3 Precision: 0.95\n",
            "Client_3 Recall: 0.87\n",
            "Client_3 F1-Score: 0.91\n",
            "\n",
            "Client_3 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94        67\n",
            "           1       0.95      0.87      0.91        47\n",
            "\n",
            "    accuracy                           0.93       114\n",
            "   macro avg       0.93      0.92      0.93       114\n",
            "weighted avg       0.93      0.93      0.93       114\n",
            "\n",
            "\n",
            "Client_3 Confusion Matrix:\n",
            " [[65  2]\n",
            " [ 6 41]]\n",
            "Client_4 training\n",
            "Client_4 Precision: 0.82\n",
            "Client_4 Recall: 0.98\n",
            "Client_4 F1-Score: 0.89\n",
            "\n",
            "Client_4 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91        67\n",
            "           1       0.82      0.98      0.89        47\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.90      0.91      0.90       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "\n",
            "Client_4 Confusion Matrix:\n",
            " [[57 10]\n",
            " [ 1 46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encrypted model SVM\n",
        "\n",
        "!pip install pandas scikit-learn syft tenseal\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import syft as sy\n",
        "import tenseal as ts\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the dataset file\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LKl8I78qANHv",
        "outputId": "508f1935-5670-4e0e-8d63-acf8e59c31bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: syft in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.15)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from syft) (75.1.0)\n",
            "Requirement already satisfied: bcrypt==4.1.2 in /usr/local/lib/python3.10/dist-packages (from syft) (4.1.2)\n",
            "Requirement already satisfied: boto3==1.34.56 in /usr/local/lib/python3.10/dist-packages (from syft) (1.34.56)\n",
            "Requirement already satisfied: forbiddenfruit==0.1.4 in /usr/local/lib/python3.10/dist-packages (from syft) (0.1.4)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from syft) (24.2)\n",
            "Requirement already satisfied: pyarrow==17.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (17.0.0)\n",
            "Requirement already satisfied: pycapnp==2.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.0)\n",
            "Requirement already satisfied: pydantic==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic[email]==2.6.0->syft) (2.6.0)\n",
            "Requirement already satisfied: pydantic-settings==2.2.1 in /usr/local/lib/python3.10/dist-packages (from syft) (2.2.1)\n",
            "Requirement already satisfied: pynacl==1.5.0 in /usr/local/lib/python3.10/dist-packages (from syft) (1.5.0)\n",
            "Requirement already satisfied: pyzmq<=25.1.1,>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from syft) (24.0.1)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.10/dist-packages (from syft) (2.32.3)\n",
            "Requirement already satisfied: RestrictedPython==7.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.0)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (from syft) (4.66.4)\n",
            "Requirement already satisfied: typeguard==4.1.5 in /usr/local/lib/python3.10/dist-packages (from syft) (4.1.5)\n",
            "Requirement already satisfied: typing-extensions==4.12.0 in /usr/local/lib/python3.10/dist-packages (from syft) (4.12.0)\n",
            "Requirement already satisfied: sherlock==0.4.1 in /usr/local/lib/python3.10/dist-packages (from sherlock[filelock]==0.4.1->syft) (0.4.1)\n",
            "Requirement already satisfied: uvicorn==0.30.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.30.0)\n",
            "Requirement already satisfied: markdown==3.5.2 in /usr/local/lib/python3.10/dist-packages (from syft) (3.5.2)\n",
            "Requirement already satisfied: fastapi==0.111.0 in /usr/local/lib/python3.10/dist-packages (from syft) (0.111.0)\n",
            "Requirement already satisfied: psutil==6.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (6.0.0)\n",
            "Requirement already satisfied: itables==1.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (1.7.1)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.10/dist-packages (from syft) (23.1.0)\n",
            "Requirement already satisfied: matplotlib<3.9.1,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (3.8.0)\n",
            "Requirement already satisfied: docker==7.1.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.1.0)\n",
            "Requirement already satisfied: kr8s==0.13.5 in /usr/local/lib/python3.10/dist-packages (from syft) (0.13.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from syft) (6.0.1)\n",
            "Requirement already satisfied: azure-storage-blob==12.19.1 in /usr/local/lib/python3.10/dist-packages (from syft) (12.19.1)\n",
            "Requirement already satisfied: ipywidgets==8.1.2 in /usr/local/lib/python3.10/dist-packages (from syft) (8.1.2)\n",
            "Requirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.1)\n",
            "Requirement already satisfied: tomli-w==1.0.0 in /usr/local/lib/python3.10/dist-packages (from syft) (1.0.0)\n",
            "Requirement already satisfied: rich==13.7.1 in /usr/local/lib/python3.10/dist-packages (from syft) (13.7.1)\n",
            "Requirement already satisfied: jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from syft) (3.1.4)\n",
            "Requirement already satisfied: tenacity==8.3.0 in /usr/local/lib/python3.10/dist-packages (from syft) (8.3.0)\n",
            "Requirement already satisfied: nh3==0.2.17 in /usr/local/lib/python3.10/dist-packages (from syft) (0.2.17)\n",
            "Requirement already satisfied: psycopg==3.1.19 in /usr/local/lib/python3.10/dist-packages (from psycopg[binary]==3.1.19->syft) (3.1.19)\n",
            "Requirement already satisfied: ipython<8.27.0 in /usr/local/lib/python3.10/dist-packages (from syft) (7.34.0)\n",
            "Requirement already satisfied: dynaconf==3.2.6 in /usr/local/lib/python3.10/dist-packages (from syft) (3.2.6)\n",
            "Requirement already satisfied: sqlalchemy==2.0.32 in /usr/local/lib/python3.10/dist-packages (from syft) (2.0.32)\n",
            "Requirement already satisfied: psycopg2-binary==2.9.9 in /usr/local/lib/python3.10/dist-packages (from syft) (2.9.9)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi==23.1.0->syft) (21.2.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (1.32.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (43.0.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob==12.19.1->syft) (0.7.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.56 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (1.34.162)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3==1.34.56->syft) (0.10.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==7.1.0->syft) (2.2.3)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.0.5)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.27.2)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (0.0.17)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (5.10.0)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (3.10.11)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.111.0->syft) (2.2.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (0.2.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.2->syft) (3.0.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.4->syft) (3.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (3.11.2)\n",
            "Requirement already satisfied: anyio>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (3.7.1)\n",
            "Requirement already satisfied: asyncache>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (0.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (1.2.2)\n",
            "Requirement already satisfied: python-box>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (7.2.0)\n",
            "Requirement already satisfied: python-jsonpath>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from kr8s==0.13.5->syft) (1.2.0)\n",
            "Requirement already satisfied: psycopg-binary==3.1.19 in /usr/local/lib/python3.10/dist-packages (from psycopg[binary]==3.1.19->syft) (3.1.19)\n",
            "Requirement already satisfied: psycopg-pool in /usr/local/lib/python3.10/dist-packages (from psycopg[pool]==3.1.19->syft) (3.2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.0->pydantic[email]==2.6.0->syft) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.0->pydantic[email]==2.6.0->syft) (2.16.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings==2.2.1->syft) (1.0.1)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl==1.5.0->syft) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->syft) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->syft) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->syft) (2.18.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from sherlock[filelock]==0.4.1->syft) (3.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy==2.0.32->syft) (3.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.30.0->uvicorn[standard]==0.30.0->syft) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.30.0->uvicorn[standard]==0.30.0->syft) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]==0.30.0->syft) (14.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.27.0->syft) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9.1,>=3.7.1->syft) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->kr8s==0.13.5->syft) (4.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.7.0->kr8s==0.13.5->syft) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0.0,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from asyncache>=0.3.1->kr8s==0.13.5->syft) (5.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl==1.5.0->syft) (2.22)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi==0.111.0->syft) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi==0.111.0->syft) (0.13.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi==0.111.0->syft) (1.0.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.27.0->syft) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->syft) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.27.0->syft) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.27.0->syft) (0.2.13)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi==0.111.0->syft) (1.5.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf8c712c-3b4c-4b71-a1e3-ac001dc23611\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf8c712c-3b4c-4b71-a1e3-ac001dc23611\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving breast-cancer.csv to breast-cancer (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (assuming the name is 'breast-cancer (4).csv')\n",
        "data = uploaded['breast-cancer (3).csv']\n",
        "# Load the dataset (assuming the name is 'breast-cancer (1).csv')\n",
        "# data = uploaded['breast-cancer (1).csv'] # This line may be redundant\n",
        "ddata = pd.read_csv('breast-cancer (3).csv')\n",
        "\n",
        "# Check the actual column names in the DataFrame\n",
        "print(ddata.columns)  # Print columns to verify the name of the target variable column\n",
        "\n",
        "# Assuming the target column is named differently, say 'diagnosis',\n",
        "# replace 'target' with the correct column name\n",
        "# For example, if the target column is named 'diagnosis':\n",
        "X = ddata.drop('diagnosis', axis=1)\n",
        "y = ddata['diagnosis']\n",
        "\n",
        "# Split data into four parts for four clients\n",
        "import numpy as np\n",
        "X_splits = np.array_split(X, 4)\n",
        "y_splits = np.array_split(y, 4)\n",
        "\n",
        "# Encrypt data using TenSEAL\n",
        "# ... (your existing code for loading and splitting data) ...\n",
        "\n",
        "# Convert 'M' and 'B' to numerical values (e.g., 1 and 0) in y_splits\n",
        "for i in range(len(y_splits)):\n",
        "    y_splits[i] = y_splits[i].map({'M': 1, 'B': 0}).astype(float)  # Map 'M' to 1 and 'B' to 0\n",
        "\n",
        "# Encrypt data using TenSEAL\n",
        "context = ts\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, id, X, y):\n",
        "        self.id = id\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = SVC\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return X_test, y_test\n",
        "\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, id, X, y):\n",
        "        self.id = id\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = SVC()\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return X_test, y_test\n",
        "\n",
        "# Create clients\n",
        "clients = [Client(f\"client_{i}\", X_splits[i], y_splits[i]) for i in range(4)]\n",
        "\n",
        "# Train models on each client\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "for client in clients:\n",
        "    X_test, y_test = client.train()\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "# Aggregate models (simple averaging for demonstration)\n",
        "import numpy as np\n",
        "\n",
        "# Aggregate models by averaging predictions instead of the tree structure directly\n",
        "def aggregate_predictions(clients, X):\n",
        "  \"\"\"\n",
        "  Aggregates predictions from multiple clients.\n",
        "\n",
        "  Args:\n",
        "    clients: List of Client objects.\n",
        "    X: Input data for prediction.\n",
        "\n",
        "  Returns:\n",
        "    Averaged predictions.\n",
        "  \"\"\"\n",
        "  all_predictions = [client.model.predict(X) for client in clients]\n",
        "  # Assuming all_predictions is a list of numpy arrays\n",
        "  return np.mean(all_predictions, axis=0)\n",
        "\n",
        "\n",
        "# Assuming you have X_splits, y_splits and clients defined as before\n",
        "\n",
        "# Train models on each client\n",
        "X_tests = []\n",
        "y_tests = []\n",
        "for client in clients:\n",
        "    X_test, y_test = client.train()\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# Instead of averaging tree structures, average predictions:\n",
        "# final_model.tree_ = sum([client.model.tree_ for client in clients]) / 4  # Remove this line\n",
        "\n",
        "# Example usage for prediction:\n",
        "predictions = aggregate_predictions(clients, X_tests[0])  # Predict on the first client's test data\n",
        "\n",
        "# Evaluate the final model\n",
        "# ... (Client class and other code remains the same) ...\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Instead of directly using final_model.predict, use aggregate_predictions:\n",
        "X_test_combined = pd.concat(X_tests)\n",
        "y_test_combined = pd.concat(y_tests)\n",
        "y_pred = aggregate_predictions(clients, X_test_combined)\n",
        "\n",
        "# Convert y_pred to binary predictions (0 or 1) by thresholding\n",
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test_combined, y_pred)\n",
        "print(f\"Final model accuracy: {accuracy}\")\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test_combined, y_pred)\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYa96eJHETEO",
        "outputId": "1058c510-88c5-4c97-86a4-e7494ac025d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model accuracy: 0.6379310344827587\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      1.00      0.78        74\n",
            "         1.0       0.00      0.00      0.00        42\n",
            "\n",
            "    accuracy                           0.64       116\n",
            "   macro avg       0.32      0.50      0.39       116\n",
            "weighted avg       0.41      0.64      0.50       116\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2BXaCMgDd_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaboost FL Model\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from io import StringIO\n",
        "from sklearn.ensemble import AdaBoostClassifier  # Assuming you want to use scikit-learn's AdaBoost\n",
        "\n",
        "# Upload the datasets manually (one for each client)\n",
        "print(\"Upload dataset1.csv for Client 1\")\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "print(\"Upload dataset2.csv for Client 2\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "print(\"Upload dataset3.csv for Client 3\")\n",
        "uploaded3 = files.upload()\n",
        "\n",
        "print(\"Upload dataset4.csv for Client 4\")\n",
        "uploaded4 = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "vzLWmlKELX2U",
        "outputId": "02c8b2ba-b984-48f0-ca5a-4be876843487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload dataset1.csv for Client 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-31045737-4ade-4d30-9779-b3aff81e9420\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-31045737-4ade-4d30-9779-b3aff81e9420\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1.csv\n",
            "Upload dataset2.csv for Client 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca8ed526-bc4e-44ee-880a-b32f990957fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca8ed526-bc4e-44ee-880a-b32f990957fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset2.csv to dataset2.csv\n",
            "Upload dataset3.csv for Client 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d1b09ce-a843-4fcf-a0f6-fcbc085200ed\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d1b09ce-a843-4fcf-a0f6-fcbc085200ed\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset3.csv to dataset3.csv\n",
            "Upload dataset4.csv for Client 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b6965a1a-bad2-4a9e-827b-8f67b6082be1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b6965a1a-bad2-4a9e-827b-8f67b6082be1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset4.csv to dataset4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load each dataset into a DataFrame (assuming CSV format)\n",
        "df1 = pd.read_csv(StringIO(uploaded1['dataset1.csv'].decode('utf-8')))\n",
        "df2 = pd.read_csv(StringIO(uploaded2['dataset2.csv'].decode('utf-8')))\n",
        "df3 = pd.read_csv(StringIO(uploaded3['dataset3.csv'].decode('utf-8')))\n",
        "df4 = pd.read_csv(StringIO(uploaded4['dataset4.csv'].decode('utf-8')))\n",
        "\n",
        "# Function to prepare the dataset (swap columns if needed, scale, and process labels)\n",
        "def prepare_dataset(df, label_column, target_column):\n",
        "    # Swap columns if needed (e.g., 'diagnosis' and 'fractal_dimension_worst')\n",
        "    df = swap_columns(df, label_column, target_column)\n",
        "\n",
        "    # Convert diagnosis to binary (e.g., \"M\" to 1, \"B\" to 0)\n",
        "    df[\"diagnostic\"] = (df[\"diagnostic\"] == \"M\").astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Define the swap_columns function\n",
        "def swap_columns(df, col1, col2):\n",
        "    col_list = list(df.columns)\n",
        "    x, y = col_list.index(col1), col_list.index(col2)\n",
        "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
        "    df = df[col_list]\n",
        "    return df\n",
        "\n",
        "# Prepare each dataset\n",
        "df1 = prepare_dataset(df1, 'diagnostic', 'perimeter_mean')\n",
        "df2 = prepare_dataset(df2, 'diagnostic', 'perimeter_mean')\n",
        "df3 = prepare_dataset(df3, 'diagnostic', 'perimeter_mean')\n",
        "df4 = prepare_dataset(df4, 'diagnostic', 'perimeter_mean')\n",
        "\n",
        "# Import libraries for machine learning and federated learning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Scaling the dataset function\n",
        "def scale_dataset(df, overSample=False):\n",
        "    # Separate features and target\n",
        "    X = df[df.columns[:-1]].values\n",
        "    Y = df[df.columns[-1]].values\n",
        "\n",
        "    # Standardize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Balance class distribution\n",
        "    if overSample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, Y = ros.fit_resample(X, Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Scaling the dataset function\n",
        "def scale_dataset(df, overSample=False):\n",
        "    # Separate features and target\n",
        "    X = df[df.columns[:-1]].values\n",
        "    # Convert target to discrete values if necessary\n",
        "    Y = df[df.columns[-1]].values\n",
        "    # Check if Y is continuous\n",
        "    if isinstance(Y[0], (int, float, complex)) and not isinstance(Y[0], bool):\n",
        "        # Convert continuous to discrete (binary classification) using a threshold\n",
        "        threshold = Y.mean()\n",
        "        Y = (Y > threshold).astype(int) # 0 or 1 based on threshold\n",
        "\n",
        "    # Standardize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Balance class distribution\n",
        "    if overSample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, Y = ros.fit_resample(X, Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Scale datasets for each client\n",
        "X_train1, Y_train1 = scale_dataset(df1, True)\n",
        "X_train2, Y_train2 = scale_dataset(df2, True)\n",
        "X_train3, Y_train3 = scale_dataset(df3, True)\n",
        "X_train4, Y_train4 = scale_dataset(df4, True)\n",
        "\n",
        "# Combine test data from all datasets (or use a separate test set if available)\n",
        "X_test = np.concatenate((X_train1, X_train2, X_train3, X_train4), axis=0)\n",
        "Y_test = np.concatenate((Y_train1, Y_train2, Y_train3, Y_train4), axis=0)\n",
        "\n",
        "# Define the AdaBoost model class\n",
        "class AdaBoostModel:\n",
        "    def __init__(self, base_estimator=None, n_estimators=50):\n",
        "        # Initialize the AdaBoost model with a base estimator (usually DecisionTreeClassifier)\n",
        "        if base_estimator is None:\n",
        "            base_estimator = DecisionTreeClassifier(max_depth=1)  # Weak learner: decision tree\n",
        "        self.model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "# Federated Learning AdaBoost implementation for multiple clients\n",
        "class Client:\n",
        "    def __init__(self, name, X_train, Y_train, X_test, Y_test):\n",
        "        self.name = name\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.model = AdaBoostModel()  # Use AdaBoost model\n",
        "\n",
        "    def local_training(self):\n",
        "        self.model.train(self.X_train, self.Y_train)\n",
        "\n",
        "    def local_evaluation(self):\n",
        "        return self.model.evaluate(self.X_test, self.Y_test)\n",
        "\n",
        "!pip install scikit-learn --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzwSaXjOLiB0",
        "outputId": "ac535b84-bf25-443f-9ba6-e4e52ce90cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "# Define the AdaBoost model class\n",
        "class AdaBoostModel:\n",
        "    def __init__(self, base_estimator=None, n_estimators=50):\n",
        "        # Initialize the AdaBoost model with a base estimator (usually DecisionTreeClassifier)\n",
        "        if base_estimator is None:\n",
        "            # For older versions of scikit-learn:\n",
        "            # base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "            # For newer versions, you can directly specify:\n",
        "            base_estimator = DecisionTreeClassifier(max_depth=1)  # Weak learner: decision tree\n",
        "\n",
        "        # Initialize AdaBoostClassifier with the base estimator and number of estimators\n",
        "        self.model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        return accuracy\n",
        "\n",
        "# Define the AdaBoost model class\n",
        "class AdaBoostModel:\n",
        "    def __init__(self, estimator=None, n_estimators=50):\n",
        "        # Initialize the AdaBoost model with an estimator (usually DecisionTreeClassifier)\n",
        "        if estimator is None:\n",
        "            estimator = DecisionTreeClassifier(max_depth=1)  # Weak learner: decision tree\n",
        "        self.model = AdaBoostClassifier(estimator=estimator, n_estimators=n_estimators)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        return accuracy\n",
        "\n",
        "# Define the AdaBoost model class\n",
        "class AdaBoostModel:\n",
        "    def __init__(self, estimator=None, n_estimators=50):\n",
        "        # Initialize the AdaBoost model with an estimator (usually DecisionTreeClassifier)\n",
        "        if estimator is None:\n",
        "            estimator = DecisionTreeClassifier(max_depth=1)  # Weak learner: decision tree\n",
        "        self.model = AdaBoostClassifier(estimator=estimator, n_estimators=n_estimators)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        #This evaluate function has been updated to also return precision, recall, and f1\n",
        "        #in addition to accuracy\n",
        "        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        precision = precision_score(Y, predictions)\n",
        "        recall = recall_score(Y, predictions)\n",
        "        f1 = f1_score(Y, predictions)\n",
        "\n",
        "        return accuracy, precision, recall, f1\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, name, X_train, Y_train, X_test, Y_test):\n",
        "        self.name = name\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.model = AdaBoostModel()  # Initialize with your AdaBoostModel\n",
        "\n",
        "    def local_training(self):\n",
        "        self.model.train(self.X_train, self.Y_train)\n",
        "\n",
        "    def local_evaluation(self):\n",
        "        return self.model.evaluate(self.X_test, self.Y_test)\n",
        "\n",
        "    def local_evaluation(self):\n",
        "        accuracy, precision, recall, f1 = self.model.evaluate(self.X_test, self.Y_test)\n",
        "        return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "# Create clients with their own datasets\n",
        "clients = [\n",
        "    Client('Client_1', X_train1, Y_train1, X_test, Y_test),\n",
        "    Client('Client_2', X_train2, Y_train2, X_test, Y_test),\n",
        "    Client('Client_3', X_train3, Y_train3, X_test, Y_test),\n",
        "    Client('Client_4', X_train4, Y_train4, X_test, Y_test),\n",
        "]\n",
        "\n",
        "# Federated learning process (aggregate models)\n",
        "def federated_learning(clients):\n",
        "    for client in clients:\n",
        "        print(f\"{client.name} training\")\n",
        "        client.local_training()\n",
        "        accuracy = client.local_evaluation()\n",
        "        print(f\"{client.name} accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Federated learning process (aggregate models)\n",
        "def federated_learning(clients):\n",
        "    for client in clients:\n",
        "        print(f\"{client.name} training\")\n",
        "        client.local_training()\n",
        "        accuracy, precision, recall, f1 = client.local_evaluation()\n",
        "        print(f\"{client.name} accuracy: {accuracy * 100:.2f}%\")\n",
        "        print(f\"{client.name} precision: {precision:.2f}\")\n",
        "        print(f\"{client.name} recall: {recall:.2f}\")\n",
        "        print(f\"{client.name} F1-score: {f1:.2f}\")\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Federated learning process (aggregate models)\n",
        "def federated_learning(clients):\n",
        "    for client in clients:\n",
        "        print(f\"{client.name} training\")\n",
        "        client.local_training()\n",
        "        accuracy, precision, recall, f1 = client.local_evaluation()\n",
        "        print(f\"{client.name} accuracy: {accuracy * 100:.2f}%\")\n",
        "        print(f\"{client.name} precision: {precision:.2f}\")\n",
        "        print(f\"{client.name} recall: {recall:.2f}\")\n",
        "        print(f\"{client.name} F1-score: {f1:.2f}\")\n",
        "\n",
        "# Run federated learning with AdaBoost\n",
        "federated_learning(clients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cWjKnABL-HU",
        "outputId": "f33d7087-9d44-466b-e1f2-d8525ba8501e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 accuracy: 79.21%\n",
            "Client_1 precision: 0.79\n",
            "Client_1 recall: 0.79\n",
            "Client_1 F1-score: 0.79\n",
            "Client_2 training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 accuracy: 80.66%\n",
            "Client_2 precision: 0.79\n",
            "Client_2 recall: 0.83\n",
            "Client_2 F1-score: 0.81\n",
            "Client_3 training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 accuracy: 80.17%\n",
            "Client_3 precision: 0.79\n",
            "Client_3 recall: 0.82\n",
            "Client_3 F1-score: 0.80\n",
            "Client_4 training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 accuracy: 72.68%\n",
            "Client_4 precision: 0.76\n",
            "Client_4 recall: 0.66\n",
            "Client_4 F1-score: 0.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encryption on Adaboost Model\n",
        "\n",
        "!pip install phe\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from io import StringIO\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import phe as paillier\n",
        "\n",
        "\n",
        "# Upload the datasets manually (one for each client)\n",
        "print(\"Upload dataset1.csv for Client 1\")\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "print(\"Upload dataset2.csv for Client 2\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "print(\"Upload dataset3.csv for Client 3\")\n",
        "uploaded3 = files.upload()\n",
        "\n",
        "print(\"Upload dataset4.csv for Client 4\")\n",
        "uploaded4 = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "CjI8E4d0L-tM",
        "outputId": "176210ed-b740-4ddb-b766-bd6b300855f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phe\n",
            "  Downloading phe-1.5.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/53.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: phe\n",
            "Successfully installed phe-1.5.0\n",
            "Upload dataset1.csv for Client 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4b9d6e3a-13f6-4647-868f-a24517ea3af4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4b9d6e3a-13f6-4647-868f-a24517ea3af4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset1.csv to dataset1 (1).csv\n",
            "Upload dataset2.csv for Client 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3eaee4a2-dad2-401f-8af2-8767d3a6340f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3eaee4a2-dad2-401f-8af2-8767d3a6340f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset2.csv to dataset2 (1).csv\n",
            "Upload dataset3.csv for Client 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d7af869-2aa4-480b-97cd-d84f5a66c76c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3d7af869-2aa4-480b-97cd-d84f5a66c76c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset3.csv to dataset3 (1).csv\n",
            "Upload dataset4.csv for Client 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-97df3156-f3ad-4173-8558-f70daf5b98e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-97df3156-f3ad-4173-8558-f70daf5b98e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset4.csv to dataset4 (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load each dataset into a DataFrame (assuming CSV format)\n",
        "df1 = pd.read_csv(StringIO(uploaded1['dataset1 (1).csv'].decode('utf-8')))\n",
        "df2 = pd.read_csv(StringIO(uploaded2['dataset2 (1).csv'].decode('utf-8')))\n",
        "df3 = pd.read_csv(StringIO(uploaded3['dataset3 (1).csv'].decode('utf-8')))\n",
        "df4 = pd.read_csv(StringIO(uploaded4['dataset4 (1).csv'].decode('utf-8')))\n",
        "\n",
        "# Function to prepare the dataset (swap columns if needed, scale, and process labels)\n",
        "def prepare_dataset(df, label_column, target_column):\n",
        "    # Swap columns if needed (e.g., 'diagnosis' and 'fractal_dimension_worst')\n",
        "    df = swap_columns(df, label_column, target_column)\n",
        "\n",
        "    # Convert diagnosis to binary (e.g., \"M\" to 1, \"B\" to 0)\n",
        "    df[\"diagnostic\"] = (df[\"diagnostic\"] == \"M\").astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Define the swap_columns function\n",
        "def swap_columns(df, col1, col2):\n",
        "    col_list = list(df.columns)\n",
        "    x, y = col_list.index(col1), col_list.index(col2)\n",
        "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
        "    df = df[col_list]\n",
        "    return df\n",
        "\n",
        "\n",
        "# Prepare each dataset\n",
        "df1 = prepare_dataset(df1, 'diagnostic', 'perimeter_mean')\n",
        "df2 = prepare_dataset(df2, 'diagnostic', 'perimeter_mean')\n",
        "df3 = prepare_dataset(df3, 'diagnostic', 'perimeter_mean')\n",
        "df4 = prepare_dataset(df4, 'diagnostic', 'perimeter_mean')\n",
        "\n",
        "# Scaling the dataset function\n",
        "def scale_dataset(df, overSample=False):\n",
        "    # Separate features and target\n",
        "    X = df[df.columns[:-1]].values\n",
        "    Y = df[df.columns[-1]].values\n",
        "\n",
        "    # Standardize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Balance class distribution\n",
        "    if overSample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, Y = ros.fit_resample(X, Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Scaling the dataset function\n",
        "def scale_dataset(df, overSample=False):\n",
        "    # Separate features and target\n",
        "    X = df[df.columns[:-1]].values\n",
        "    # Convert target to discrete values if necessary\n",
        "    Y = df[df.columns[-1]].values\n",
        "    # Check if Y is continuous\n",
        "    if isinstance(Y[0], (int, float, complex)) and not isinstance(Y[0], bool):\n",
        "        # Convert continuous to discrete (binary classification) using a threshold\n",
        "        threshold = Y.mean()\n",
        "        Y = (Y > threshold).astype(int) # 0 or 1 based on threshold\n",
        "\n",
        "    # Standardize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Balance class distribution\n",
        "    if overSample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, Y = ros.fit_resample(X, Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Scale datasets for each client\n",
        "X_train1, Y_train1 = scale_dataset(df1, True)\n",
        "X_train2, Y_train2 = scale_dataset(df2, True)\n",
        "X_train3, Y_train3 = scale_dataset(df3, True)\n",
        "X_train4, Y_train4 = scale_dataset(df4, True)\n",
        "\n",
        "# Combine test data from all datasets (or use a separate test set if available)\n",
        "X_test = np.concatenate((X_train1, X_train2, X_train3, X_train4), axis=0)\n",
        "Y_test = np.concatenate((Y_train1, Y_train2, Y_train3, Y_train4), axis=0)\n",
        "\n",
        "# Define the AdaBoost model class\n",
        "class AdaBoostModel:\n",
        "    def __init__(self, base_estimator=None, n_estimators=50):\n",
        "        # Initialize the AdaBoost model with a base estimator (usually DecisionTreeClassifier)\n",
        "        if base_estimator is None:\n",
        "            base_estimator = DecisionTreeClassifier(max_depth=1)  # Weak learner: decision tree\n",
        "        self.model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        return accuracy\n",
        "\n",
        "# Federated Learning AdaBoost implementation for multiple clients\n",
        "class Client:\n",
        "    def __init__(self, name, X_train, Y_train, X_test, Y_test):\n",
        "        self.name = name\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.model = AdaBoostModel()  # Use AdaBoost model\n",
        "\n",
        "    def local_training(self):\n",
        "        self.model.train(self.X_train, self.Y_train)\n",
        "\n",
        "    def local_evaluation(self):\n",
        "        return self.model.evaluate(self.X_test, self.Y_test)\n",
        "\n",
        "\n",
        "# Homomorphic Encryption Class\n",
        "class HomomorphicEncryption:\n",
        "    def __init__(self):\n",
        "        self.public_key, self.private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "    def encrypt_data(self, data):\n",
        "        encrypted_data = [self.public_key.encrypt(x) for x in data]\n",
        "        return encrypted_data\n",
        "\n",
        "    def decrypt_data(self, encrypted_data):\n",
        "        decrypted_data = [self.private_key.decrypt(x) for x in encrypted_data]\n",
        "        return decrypted_data\n",
        "\n",
        "# Define the AdaBoost model class (modified to use homomorphic encryption)\n",
        "class AdaBoostModel:\n",
        "    def __init__(self, estimator=None, n_estimators=50, encryption=None):\n",
        "        # Initialize the AdaBoost model with an estimator (usually DecisionTreeClassifier)\n",
        "        if estimator is None:\n",
        "            estimator = DecisionTreeClassifier(max_depth=1)  # Weak learner: decision tree\n",
        "        self.model = AdaBoostClassifier(estimator=estimator, n_estimators=n_estimators)\n",
        "        self.encryption = encryption\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        if self.encryption:\n",
        "            # Encrypt data before training\n",
        "            X_encrypted = self.encryption.encrypt_data(X.flatten())  # Encrypt data\n",
        "\n",
        "            # Need to further adapt the model training to handle encrypted data\n",
        "            # This is a complex process, you might need to explore\n",
        "            # homomorphic operations with libraries like TensorFlow/PyTorch\n",
        "            # or customized approaches\n",
        "            # This example simulates partial encrypted training\n",
        "            self.model.fit(np.reshape(X_encrypted, X.shape), Y)\n",
        "        else:\n",
        "            self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.encryption:\n",
        "            # Decrypt the predictions\n",
        "            encrypted_predictions = self.model.predict(X)\n",
        "            predictions = self.encryption.decrypt_data(encrypted_predictions)  # Decrypt predictions\n",
        "            return predictions\n",
        "        else:\n",
        "            return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = accuracy_score(Y, predictions)\n",
        "        precision = precision_score(Y, predictions)\n",
        "        recall = recall_score(Y, predictions)\n",
        "        f1 = f1_score(Y, predictions)\n",
        "\n",
        "        return accuracy, precision, recall, f1\n",
        "\n",
        "# Federated Learning process with encryption (simplified)\n",
        "class Client:\n",
        "    def __init__(self, name, X_train, Y_train, X_test, Y_test, encryption=None):\n",
        "        self.name = name\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.model = AdaBoostModel(encryption=encryption)\n",
        "\n",
        "    def local_training(self):\n",
        "        self.model.train(self.X_train, self.Y_train)\n",
        "\n",
        "    def local_evaluation(self):\n",
        "        accuracy, precision, recall, f1 = self.model.evaluate(self.X_test, self.Y_test)\n",
        "        return accuracy, precision, recall, f1\n",
        "\n",
        "# Create clients with encryption (optional)\n",
        "encryption_instance = HomomorphicEncryption()  # Create encryption instance\n",
        "clients = [\n",
        "    Client('Client_1', X_train1, Y_train1, X_test, Y_test, encryption=encryption_instance),\n",
        "]\n",
        "\n",
        "# Run federated learning with AdaBoost (with encryption)\n",
        "from io import StringIO\n",
        "from sklearn.ensemble import AdaBoostClassifier  # Assuming you want to use scikit-learn's AdaBoost\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the federated_learning function\n",
        "def federated_learning(clients, rounds=10):\n",
        "    \"\"\"\n",
        "    Simulates a basic federated learning process.\n",
        "\n",
        "    Args:\n",
        "        clients (list): List of Client objects.\n",
        "        rounds (int): Number of federated learning rounds.\n",
        "    \"\"\"\n",
        "    for round_num in range(rounds):\n",
        "        print(f\"Round {round_num + 1}\")\n",
        "        # Local training on each client\n",
        "        for client in clients:\n",
        "            client.local_training()\n",
        "            accuracy, precision, recall, f1 = client.local_evaluation()\n",
        "            print(f\"{client.name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "        # Here, you would typically aggregate the models from different clients\n",
        "        # and update the global model (not implemented in this basic example)\n",
        "\n",
        "#  apply adaboost on  federated leaning on test file of 1200 datasets, to check code working\n",
        "\n",
        "encryption_instance = HomomorphicEncryption()  # Create encryption instance\n",
        "clients = [\n",
        "    Client('Client_1', X_train1, Y_train1, X_test[:1200], Y_test[:1200]),  # Used 1200 datasets for testing\n",
        "    Client('Client_2', X_train2, Y_train2, X_test[:1200], Y_test[:1200]),\n",
        "    Client('Client_3', X_train3, Y_train3, X_test[:1200], Y_test[:1200]),\n",
        "    Client('Client_4', X_train4, Y_train4, X_test[:1200], Y_test[:1200]),\n",
        "]\n",
        "\n",
        "\n",
        "# Run federated learning with AdaBoost (with encryption - using 1200 test datasets)\n",
        "federated_learning(clients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj95O5ftM_Lb",
        "outputId": "dd7a98d5-a906-4260-f4c2-30eb16dd08e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n",
            "Round 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_1 - Accuracy: 0.8450, Precision: 0.7527, Recall: 0.8896, F1: 0.8155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_2 - Accuracy: 0.7808, Precision: 0.6874, Recall: 0.7900, F1: 0.7351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_3 - Accuracy: 0.7892, Precision: 0.7029, Recall: 0.7835, F1: 0.7410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client_4 - Accuracy: 0.7475, Precision: 0.6747, Recall: 0.6645, F1: 0.6696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCZa578TOG__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}